[2025-03-25 14:39:54 root] (main.py 258): INFO Namespace(model='/workspace/volume/inference-soft-data/AE/llm/models/llama-7b-hf', cache_dir='./cache', output_dir='./log/llama-7b-w4a7', save_dir=None, resume=None, real_quant=False, calib_dataset='wikitext2', nsamples=128, batch_size=1, seed=2, tasks='piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', eval_ppl=True, num_fewshot=0, wbits=4, abits=7, group_size=None, alpha=0.5, let_lr=0.005, lwc_lr=0.01, wd=0, epochs=10, let=True, lwc=True, aug_loss=True, symmetric=False, disable_zero_point=False, a_dynamic_method='per_token', w_dynamic_method='per_channel', limit=-1, multigpu=False, deactive_amp=False, attn_implementation='eager', net=None, act_scales=None, act_shifts=None)
[2025-03-25 14:40:35 root] (main.py 324): INFO === start quantization ===
[2025-03-25 14:41:48 root] (omniquant.py 50): INFO Starting ...
[2025-03-25 14:41:49 root] (omniquant.py 193): INFO === Start quantize layer 0 ===
[2025-03-25 14:42:04 root] (omniquant.py 274): INFO layer 0 iter 0 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:42:17 root] (omniquant.py 274): INFO layer 0 iter 1 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:42:29 root] (omniquant.py 274): INFO layer 0 iter 2 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:42:42 root] (omniquant.py 274): INFO layer 0 iter 3 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:42:54 root] (omniquant.py 274): INFO layer 0 iter 4 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:43:07 root] (omniquant.py 274): INFO layer 0 iter 5 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:43:19 root] (omniquant.py 274): INFO layer 0 iter 6 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:43:32 root] (omniquant.py 274): INFO layer 0 iter 7 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:43:44 root] (omniquant.py 274): INFO layer 0 iter 8 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:43:57 root] (omniquant.py 274): INFO layer 0 iter 9 loss:0.00012255500769242644 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:43:59 root] (omniquant.py 193): INFO === Start quantize layer 1 ===
[2025-03-25 14:44:14 root] (omniquant.py 274): INFO layer 1 iter 0 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:44:27 root] (omniquant.py 274): INFO layer 1 iter 1 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:44:39 root] (omniquant.py 274): INFO layer 1 iter 2 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:44:52 root] (omniquant.py 274): INFO layer 1 iter 3 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:45:04 root] (omniquant.py 274): INFO layer 1 iter 4 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:45:17 root] (omniquant.py 274): INFO layer 1 iter 5 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:45:30 root] (omniquant.py 274): INFO layer 1 iter 6 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:45:42 root] (omniquant.py 274): INFO layer 1 iter 7 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:45:55 root] (omniquant.py 274): INFO layer 1 iter 8 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:46:07 root] (omniquant.py 274): INFO layer 1 iter 9 loss:0.0006357640959322453 norm:nan max memory_allocated 14379.7021484375 
[2025-03-25 14:46:09 root] (omniquant.py 193): INFO === Start quantize layer 2 ===
[2025-03-25 14:46:25 root] (omniquant.py 274): INFO layer 2 iter 0 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:46:38 root] (omniquant.py 274): INFO layer 2 iter 1 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:46:50 root] (omniquant.py 274): INFO layer 2 iter 2 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:47:03 root] (omniquant.py 274): INFO layer 2 iter 3 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:47:16 root] (omniquant.py 274): INFO layer 2 iter 4 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:47:28 root] (omniquant.py 274): INFO layer 2 iter 5 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:47:41 root] (omniquant.py 274): INFO layer 2 iter 6 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:47:53 root] (omniquant.py 274): INFO layer 2 iter 7 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:48:06 root] (omniquant.py 274): INFO layer 2 iter 8 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:48:18 root] (omniquant.py 274): INFO layer 2 iter 9 loss:0.004986234940588474 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:48:21 root] (omniquant.py 193): INFO === Start quantize layer 3 ===
[2025-03-25 14:48:36 root] (omniquant.py 274): INFO layer 3 iter 0 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:48:49 root] (omniquant.py 274): INFO layer 3 iter 1 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:49:01 root] (omniquant.py 274): INFO layer 3 iter 2 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:49:14 root] (omniquant.py 274): INFO layer 3 iter 3 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:49:26 root] (omniquant.py 274): INFO layer 3 iter 4 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:49:39 root] (omniquant.py 274): INFO layer 3 iter 5 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:49:51 root] (omniquant.py 274): INFO layer 3 iter 6 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:50:04 root] (omniquant.py 274): INFO layer 3 iter 7 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:50:17 root] (omniquant.py 274): INFO layer 3 iter 8 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:50:29 root] (omniquant.py 274): INFO layer 3 iter 9 loss:0.004313044250011444 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:50:31 root] (omniquant.py 193): INFO === Start quantize layer 4 ===
[2025-03-25 14:50:47 root] (omniquant.py 274): INFO layer 4 iter 0 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:50:59 root] (omniquant.py 274): INFO layer 4 iter 1 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:51:12 root] (omniquant.py 274): INFO layer 4 iter 2 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:51:24 root] (omniquant.py 274): INFO layer 4 iter 3 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:51:37 root] (omniquant.py 274): INFO layer 4 iter 4 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:51:49 root] (omniquant.py 274): INFO layer 4 iter 5 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:52:02 root] (omniquant.py 274): INFO layer 4 iter 6 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:52:14 root] (omniquant.py 274): INFO layer 4 iter 7 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:52:27 root] (omniquant.py 274): INFO layer 4 iter 8 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:52:39 root] (omniquant.py 274): INFO layer 4 iter 9 loss:0.0060615320689976215 norm:nan max memory_allocated 14382.3896484375 
[2025-03-25 14:52:41 root] (omniquant.py 193): INFO === Start quantize layer 5 ===
[2025-03-25 14:52:57 root] (omniquant.py 274): INFO layer 5 iter 0 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:53:10 root] (omniquant.py 274): INFO layer 5 iter 1 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:53:22 root] (omniquant.py 274): INFO layer 5 iter 2 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:53:35 root] (omniquant.py 274): INFO layer 5 iter 3 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:53:47 root] (omniquant.py 274): INFO layer 5 iter 4 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:54:00 root] (omniquant.py 274): INFO layer 5 iter 5 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:54:12 root] (omniquant.py 274): INFO layer 5 iter 6 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:54:25 root] (omniquant.py 274): INFO layer 5 iter 7 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:54:38 root] (omniquant.py 274): INFO layer 5 iter 8 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:54:50 root] (omniquant.py 274): INFO layer 5 iter 9 loss:0.008691629394888878 norm:nan max memory_allocated 14383.0380859375 
[2025-03-25 14:54:52 root] (omniquant.py 193): INFO === Start quantize layer 6 ===
[2025-03-25 14:55:08 root] (omniquant.py 274): INFO layer 6 iter 0 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:55:20 root] (omniquant.py 274): INFO layer 6 iter 1 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:55:33 root] (omniquant.py 274): INFO layer 6 iter 2 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:55:45 root] (omniquant.py 274): INFO layer 6 iter 3 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:55:58 root] (omniquant.py 274): INFO layer 6 iter 4 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:56:10 root] (omniquant.py 274): INFO layer 6 iter 5 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:56:23 root] (omniquant.py 274): INFO layer 6 iter 6 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:56:35 root] (omniquant.py 274): INFO layer 6 iter 7 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:56:48 root] (omniquant.py 274): INFO layer 6 iter 8 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:57:00 root] (omniquant.py 274): INFO layer 6 iter 9 loss:0.01235787570476532 norm:nan max memory_allocated 14384.8583984375 
[2025-03-25 14:57:03 root] (omniquant.py 193): INFO === Start quantize layer 7 ===
[2025-03-25 14:57:18 root] (omniquant.py 274): INFO layer 7 iter 0 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:57:31 root] (omniquant.py 274): INFO layer 7 iter 1 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:57:43 root] (omniquant.py 274): INFO layer 7 iter 2 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:57:56 root] (omniquant.py 274): INFO layer 7 iter 3 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:58:08 root] (omniquant.py 274): INFO layer 7 iter 4 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:58:21 root] (omniquant.py 274): INFO layer 7 iter 5 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:58:33 root] (omniquant.py 274): INFO layer 7 iter 6 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:58:46 root] (omniquant.py 274): INFO layer 7 iter 7 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:58:58 root] (omniquant.py 274): INFO layer 7 iter 8 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:59:11 root] (omniquant.py 274): INFO layer 7 iter 9 loss:0.01710090972483158 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:59:13 root] (omniquant.py 193): INFO === Start quantize layer 8 ===
[2025-03-25 14:59:29 root] (omniquant.py 274): INFO layer 8 iter 0 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:59:41 root] (omniquant.py 274): INFO layer 8 iter 1 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 14:59:54 root] (omniquant.py 274): INFO layer 8 iter 2 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 15:00:06 root] (omniquant.py 274): INFO layer 8 iter 3 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 15:00:19 root] (omniquant.py 274): INFO layer 8 iter 4 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 15:00:32 root] (omniquant.py 274): INFO layer 8 iter 5 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 15:00:44 root] (omniquant.py 274): INFO layer 8 iter 6 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 15:00:57 root] (omniquant.py 274): INFO layer 8 iter 7 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 15:01:09 root] (omniquant.py 274): INFO layer 8 iter 8 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 15:01:22 root] (omniquant.py 274): INFO layer 8 iter 9 loss:0.022117873653769493 norm:nan max memory_allocated 14385.7724609375 
[2025-03-25 15:01:24 root] (omniquant.py 193): INFO === Start quantize layer 9 ===
[2025-03-25 15:01:40 root] (omniquant.py 274): INFO layer 9 iter 0 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:01:52 root] (omniquant.py 274): INFO layer 9 iter 1 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:02:05 root] (omniquant.py 274): INFO layer 9 iter 2 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:02:17 root] (omniquant.py 274): INFO layer 9 iter 3 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:02:30 root] (omniquant.py 274): INFO layer 9 iter 4 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:02:42 root] (omniquant.py 274): INFO layer 9 iter 5 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:02:55 root] (omniquant.py 274): INFO layer 9 iter 6 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:03:08 root] (omniquant.py 274): INFO layer 9 iter 7 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:03:20 root] (omniquant.py 274): INFO layer 9 iter 8 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:03:33 root] (omniquant.py 274): INFO layer 9 iter 9 loss:0.02930602803826332 norm:nan max memory_allocated 14386.5068359375 
[2025-03-25 15:03:35 root] (omniquant.py 193): INFO === Start quantize layer 10 ===
[2025-03-25 15:03:50 root] (omniquant.py 274): INFO layer 10 iter 0 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:04:03 root] (omniquant.py 274): INFO layer 10 iter 1 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:04:15 root] (omniquant.py 274): INFO layer 10 iter 2 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:04:28 root] (omniquant.py 274): INFO layer 10 iter 3 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:04:41 root] (omniquant.py 274): INFO layer 10 iter 4 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:04:53 root] (omniquant.py 274): INFO layer 10 iter 5 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:05:06 root] (omniquant.py 274): INFO layer 10 iter 6 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:05:18 root] (omniquant.py 274): INFO layer 10 iter 7 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:05:31 root] (omniquant.py 274): INFO layer 10 iter 8 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:05:43 root] (omniquant.py 274): INFO layer 10 iter 9 loss:0.035867925733327866 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:05:46 root] (omniquant.py 193): INFO === Start quantize layer 11 ===
[2025-03-25 15:06:01 root] (omniquant.py 274): INFO layer 11 iter 0 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:06:14 root] (omniquant.py 274): INFO layer 11 iter 1 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:06:26 root] (omniquant.py 274): INFO layer 11 iter 2 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:06:39 root] (omniquant.py 274): INFO layer 11 iter 3 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:06:52 root] (omniquant.py 274): INFO layer 11 iter 4 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:07:04 root] (omniquant.py 274): INFO layer 11 iter 5 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:07:17 root] (omniquant.py 274): INFO layer 11 iter 6 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:07:29 root] (omniquant.py 274): INFO layer 11 iter 7 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:07:42 root] (omniquant.py 274): INFO layer 11 iter 8 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:07:54 root] (omniquant.py 274): INFO layer 11 iter 9 loss:0.043864719569683075 norm:nan max memory_allocated 14388.3740234375 
[2025-03-25 15:07:57 root] (omniquant.py 193): INFO === Start quantize layer 12 ===
[2025-03-25 15:08:12 root] (omniquant.py 274): INFO layer 12 iter 0 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:08:25 root] (omniquant.py 274): INFO layer 12 iter 1 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:08:37 root] (omniquant.py 274): INFO layer 12 iter 2 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:08:50 root] (omniquant.py 274): INFO layer 12 iter 3 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:09:02 root] (omniquant.py 274): INFO layer 12 iter 4 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:09:15 root] (omniquant.py 274): INFO layer 12 iter 5 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:09:28 root] (omniquant.py 274): INFO layer 12 iter 6 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:09:40 root] (omniquant.py 274): INFO layer 12 iter 7 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:09:53 root] (omniquant.py 274): INFO layer 12 iter 8 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:10:05 root] (omniquant.py 274): INFO layer 12 iter 9 loss:0.052840471267700195 norm:nan max memory_allocated 14390.1083984375 
[2025-03-25 15:10:07 root] (omniquant.py 193): INFO === Start quantize layer 13 ===
[2025-03-25 15:10:23 root] (omniquant.py 274): INFO layer 13 iter 0 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:10:35 root] (omniquant.py 274): INFO layer 13 iter 1 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:10:48 root] (omniquant.py 274): INFO layer 13 iter 2 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:11:00 root] (omniquant.py 274): INFO layer 13 iter 3 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:11:13 root] (omniquant.py 274): INFO layer 13 iter 4 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:11:26 root] (omniquant.py 274): INFO layer 13 iter 5 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:11:38 root] (omniquant.py 274): INFO layer 13 iter 6 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:11:51 root] (omniquant.py 274): INFO layer 13 iter 7 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:12:03 root] (omniquant.py 274): INFO layer 13 iter 8 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:12:16 root] (omniquant.py 274): INFO layer 13 iter 9 loss:0.06276577711105347 norm:nan max memory_allocated 14390.9755859375 
[2025-03-25 15:12:18 root] (omniquant.py 193): INFO === Start quantize layer 14 ===
[2025-03-25 15:12:33 root] (omniquant.py 274): INFO layer 14 iter 0 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:12:46 root] (omniquant.py 274): INFO layer 14 iter 1 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:12:58 root] (omniquant.py 274): INFO layer 14 iter 2 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:13:11 root] (omniquant.py 274): INFO layer 14 iter 3 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:13:24 root] (omniquant.py 274): INFO layer 14 iter 4 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:13:36 root] (omniquant.py 274): INFO layer 14 iter 5 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:13:49 root] (omniquant.py 274): INFO layer 14 iter 6 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:14:01 root] (omniquant.py 274): INFO layer 14 iter 7 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:14:14 root] (omniquant.py 274): INFO layer 14 iter 8 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:14:26 root] (omniquant.py 274): INFO layer 14 iter 9 loss:0.07694480568170547 norm:nan max memory_allocated 14391.8427734375 
[2025-03-25 15:14:28 root] (omniquant.py 193): INFO === Start quantize layer 15 ===
[2025-03-25 15:14:44 root] (omniquant.py 274): INFO layer 15 iter 0 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:14:56 root] (omniquant.py 274): INFO layer 15 iter 1 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:15:09 root] (omniquant.py 274): INFO layer 15 iter 2 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:15:21 root] (omniquant.py 274): INFO layer 15 iter 3 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:15:34 root] (omniquant.py 274): INFO layer 15 iter 4 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:15:46 root] (omniquant.py 274): INFO layer 15 iter 5 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:15:59 root] (omniquant.py 274): INFO layer 15 iter 6 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:16:12 root] (omniquant.py 274): INFO layer 15 iter 7 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:16:24 root] (omniquant.py 274): INFO layer 15 iter 8 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:16:37 root] (omniquant.py 274): INFO layer 15 iter 9 loss:0.09193094074726105 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:16:39 root] (omniquant.py 193): INFO === Start quantize layer 16 ===
[2025-03-25 15:16:54 root] (omniquant.py 274): INFO layer 16 iter 0 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:17:07 root] (omniquant.py 274): INFO layer 16 iter 1 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:17:20 root] (omniquant.py 274): INFO layer 16 iter 2 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:17:32 root] (omniquant.py 274): INFO layer 16 iter 3 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:17:45 root] (omniquant.py 274): INFO layer 16 iter 4 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:17:57 root] (omniquant.py 274): INFO layer 16 iter 5 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:18:10 root] (omniquant.py 274): INFO layer 16 iter 6 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:18:22 root] (omniquant.py 274): INFO layer 16 iter 7 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:18:35 root] (omniquant.py 274): INFO layer 16 iter 8 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:18:48 root] (omniquant.py 274): INFO layer 16 iter 9 loss:0.11394250392913818 norm:nan max memory_allocated 14392.6630859375 
[2025-03-25 15:18:50 root] (omniquant.py 193): INFO === Start quantize layer 17 ===
[2025-03-25 15:19:05 root] (omniquant.py 274): INFO layer 17 iter 0 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:19:18 root] (omniquant.py 274): INFO layer 17 iter 1 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:19:31 root] (omniquant.py 274): INFO layer 17 iter 2 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:19:43 root] (omniquant.py 274): INFO layer 17 iter 3 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:19:56 root] (omniquant.py 274): INFO layer 17 iter 4 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:20:08 root] (omniquant.py 274): INFO layer 17 iter 5 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:20:21 root] (omniquant.py 274): INFO layer 17 iter 6 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:20:33 root] (omniquant.py 274): INFO layer 17 iter 7 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:20:46 root] (omniquant.py 274): INFO layer 17 iter 8 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:20:59 root] (omniquant.py 274): INFO layer 17 iter 9 loss:0.1446915566921234 norm:nan max memory_allocated 14393.4443359375 
[2025-03-25 15:21:01 root] (omniquant.py 193): INFO === Start quantize layer 18 ===
[2025-03-25 15:21:16 root] (omniquant.py 274): INFO layer 18 iter 0 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:21:29 root] (omniquant.py 274): INFO layer 18 iter 1 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:21:42 root] (omniquant.py 274): INFO layer 18 iter 2 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:21:54 root] (omniquant.py 274): INFO layer 18 iter 3 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:22:07 root] (omniquant.py 274): INFO layer 18 iter 4 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:22:19 root] (omniquant.py 274): INFO layer 18 iter 5 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:22:32 root] (omniquant.py 274): INFO layer 18 iter 6 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:22:44 root] (omniquant.py 274): INFO layer 18 iter 7 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:22:57 root] (omniquant.py 274): INFO layer 18 iter 8 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:23:09 root] (omniquant.py 274): INFO layer 18 iter 9 loss:0.17932333052158356 norm:nan max memory_allocated 14394.3115234375 
[2025-03-25 15:23:11 root] (omniquant.py 193): INFO === Start quantize layer 19 ===
[2025-03-25 15:23:27 root] (omniquant.py 274): INFO layer 19 iter 0 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:23:39 root] (omniquant.py 274): INFO layer 19 iter 1 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:23:52 root] (omniquant.py 274): INFO layer 19 iter 2 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:24:05 root] (omniquant.py 274): INFO layer 19 iter 3 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:24:17 root] (omniquant.py 274): INFO layer 19 iter 4 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:24:30 root] (omniquant.py 274): INFO layer 19 iter 5 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:24:42 root] (omniquant.py 274): INFO layer 19 iter 6 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:24:55 root] (omniquant.py 274): INFO layer 19 iter 7 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:25:07 root] (omniquant.py 274): INFO layer 19 iter 8 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:25:20 root] (omniquant.py 274): INFO layer 19 iter 9 loss:0.2240895926952362 norm:nan max memory_allocated 14395.1787109375 
[2025-03-25 15:25:22 root] (omniquant.py 193): INFO === Start quantize layer 20 ===
[2025-03-25 15:25:37 root] (omniquant.py 274): INFO layer 20 iter 0 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:25:50 root] (omniquant.py 274): INFO layer 20 iter 1 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:26:02 root] (omniquant.py 274): INFO layer 20 iter 2 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:26:15 root] (omniquant.py 274): INFO layer 20 iter 3 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:26:27 root] (omniquant.py 274): INFO layer 20 iter 4 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:26:40 root] (omniquant.py 274): INFO layer 20 iter 5 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:26:53 root] (omniquant.py 274): INFO layer 20 iter 6 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:27:05 root] (omniquant.py 274): INFO layer 20 iter 7 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:27:18 root] (omniquant.py 274): INFO layer 20 iter 8 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:27:30 root] (omniquant.py 274): INFO layer 20 iter 9 loss:0.2796644866466522 norm:nan max memory_allocated 14396.0458984375 
[2025-03-25 15:27:32 root] (omniquant.py 193): INFO === Start quantize layer 21 ===
[2025-03-25 15:27:48 root] (omniquant.py 274): INFO layer 21 iter 0 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:28:00 root] (omniquant.py 274): INFO layer 21 iter 1 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:28:13 root] (omniquant.py 274): INFO layer 21 iter 2 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:28:26 root] (omniquant.py 274): INFO layer 21 iter 3 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:28:38 root] (omniquant.py 274): INFO layer 21 iter 4 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:28:51 root] (omniquant.py 274): INFO layer 21 iter 5 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:29:03 root] (omniquant.py 274): INFO layer 21 iter 6 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:29:16 root] (omniquant.py 274): INFO layer 21 iter 7 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:29:28 root] (omniquant.py 274): INFO layer 21 iter 8 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:29:41 root] (omniquant.py 274): INFO layer 21 iter 9 loss:0.34041348099708557 norm:nan max memory_allocated 14396.9130859375 
[2025-03-25 15:29:43 root] (omniquant.py 193): INFO === Start quantize layer 22 ===
[2025-03-25 15:29:59 root] (omniquant.py 274): INFO layer 22 iter 0 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:30:11 root] (omniquant.py 274): INFO layer 22 iter 1 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:30:24 root] (omniquant.py 274): INFO layer 22 iter 2 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:30:36 root] (omniquant.py 274): INFO layer 22 iter 3 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:30:49 root] (omniquant.py 274): INFO layer 22 iter 4 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:31:01 root] (omniquant.py 274): INFO layer 22 iter 5 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:31:14 root] (omniquant.py 274): INFO layer 22 iter 6 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:31:26 root] (omniquant.py 274): INFO layer 22 iter 7 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:31:39 root] (omniquant.py 274): INFO layer 22 iter 8 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:31:51 root] (omniquant.py 274): INFO layer 22 iter 9 loss:0.4081632196903229 norm:nan max memory_allocated 14397.7802734375 
[2025-03-25 15:31:54 root] (omniquant.py 193): INFO === Start quantize layer 23 ===
[2025-03-25 15:32:09 root] (omniquant.py 274): INFO layer 23 iter 0 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:32:22 root] (omniquant.py 274): INFO layer 23 iter 1 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:32:34 root] (omniquant.py 274): INFO layer 23 iter 2 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:32:47 root] (omniquant.py 274): INFO layer 23 iter 3 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:32:59 root] (omniquant.py 274): INFO layer 23 iter 4 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:33:12 root] (omniquant.py 274): INFO layer 23 iter 5 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:33:24 root] (omniquant.py 274): INFO layer 23 iter 6 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:33:37 root] (omniquant.py 274): INFO layer 23 iter 7 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:33:49 root] (omniquant.py 274): INFO layer 23 iter 8 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:34:02 root] (omniquant.py 274): INFO layer 23 iter 9 loss:0.4950115978717804 norm:nan max memory_allocated 14399.6474609375 
[2025-03-25 15:34:05 root] (omniquant.py 193): INFO === Start quantize layer 24 ===
[2025-03-25 15:34:20 root] (omniquant.py 274): INFO layer 24 iter 0 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:34:33 root] (omniquant.py 274): INFO layer 24 iter 1 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:34:45 root] (omniquant.py 274): INFO layer 24 iter 2 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:34:58 root] (omniquant.py 274): INFO layer 24 iter 3 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:35:10 root] (omniquant.py 274): INFO layer 24 iter 4 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:35:23 root] (omniquant.py 274): INFO layer 24 iter 5 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:35:35 root] (omniquant.py 274): INFO layer 24 iter 6 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:35:48 root] (omniquant.py 274): INFO layer 24 iter 7 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:36:00 root] (omniquant.py 274): INFO layer 24 iter 8 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:36:13 root] (omniquant.py 274): INFO layer 24 iter 9 loss:0.5754023790359497 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:36:15 root] (omniquant.py 193): INFO === Start quantize layer 25 ===
[2025-03-25 15:36:31 root] (omniquant.py 274): INFO layer 25 iter 0 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:36:43 root] (omniquant.py 274): INFO layer 25 iter 1 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:36:56 root] (omniquant.py 274): INFO layer 25 iter 2 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:37:08 root] (omniquant.py 274): INFO layer 25 iter 3 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:37:21 root] (omniquant.py 274): INFO layer 25 iter 4 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:37:33 root] (omniquant.py 274): INFO layer 25 iter 5 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:37:46 root] (omniquant.py 274): INFO layer 25 iter 6 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:37:59 root] (omniquant.py 274): INFO layer 25 iter 7 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:38:11 root] (omniquant.py 274): INFO layer 25 iter 8 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:38:24 root] (omniquant.py 274): INFO layer 25 iter 9 loss:0.6724792122840881 norm:nan max memory_allocated 14400.4677734375 
[2025-03-25 15:38:26 root] (omniquant.py 193): INFO === Start quantize layer 26 ===
[2025-03-25 15:38:41 root] (omniquant.py 274): INFO layer 26 iter 0 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:38:54 root] (omniquant.py 274): INFO layer 26 iter 1 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:39:07 root] (omniquant.py 274): INFO layer 26 iter 2 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:39:19 root] (omniquant.py 274): INFO layer 26 iter 3 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:39:32 root] (omniquant.py 274): INFO layer 26 iter 4 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:39:44 root] (omniquant.py 274): INFO layer 26 iter 5 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:39:57 root] (omniquant.py 274): INFO layer 26 iter 6 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:40:09 root] (omniquant.py 274): INFO layer 26 iter 7 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:40:22 root] (omniquant.py 274): INFO layer 26 iter 8 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:40:34 root] (omniquant.py 274): INFO layer 26 iter 9 loss:0.785147488117218 norm:nan max memory_allocated 14401.2490234375 
[2025-03-25 15:40:36 root] (omniquant.py 193): INFO === Start quantize layer 27 ===
[2025-03-25 15:40:52 root] (omniquant.py 274): INFO layer 27 iter 0 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:41:04 root] (omniquant.py 274): INFO layer 27 iter 1 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:41:17 root] (omniquant.py 274): INFO layer 27 iter 2 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:41:30 root] (omniquant.py 274): INFO layer 27 iter 3 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:41:42 root] (omniquant.py 274): INFO layer 27 iter 4 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:41:55 root] (omniquant.py 274): INFO layer 27 iter 5 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:42:07 root] (omniquant.py 274): INFO layer 27 iter 6 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:42:20 root] (omniquant.py 274): INFO layer 27 iter 7 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:42:32 root] (omniquant.py 274): INFO layer 27 iter 8 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:42:45 root] (omniquant.py 274): INFO layer 27 iter 9 loss:0.8832371234893799 norm:nan max memory_allocated 14402.1162109375 
[2025-03-25 15:42:47 root] (omniquant.py 193): INFO === Start quantize layer 28 ===
[2025-03-25 15:43:03 root] (omniquant.py 274): INFO layer 28 iter 0 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:43:15 root] (omniquant.py 274): INFO layer 28 iter 1 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:43:28 root] (omniquant.py 274): INFO layer 28 iter 2 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:43:40 root] (omniquant.py 274): INFO layer 28 iter 3 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:43:53 root] (omniquant.py 274): INFO layer 28 iter 4 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:44:05 root] (omniquant.py 274): INFO layer 28 iter 5 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:44:18 root] (omniquant.py 274): INFO layer 28 iter 6 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:44:31 root] (omniquant.py 274): INFO layer 28 iter 7 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:44:43 root] (omniquant.py 274): INFO layer 28 iter 8 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:44:56 root] (omniquant.py 274): INFO layer 28 iter 9 loss:1.0601060390472412 norm:nan max memory_allocated 14402.9833984375 
[2025-03-25 15:44:58 root] (omniquant.py 193): INFO === Start quantize layer 29 ===
[2025-03-25 15:45:13 root] (omniquant.py 274): INFO layer 29 iter 0 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:45:26 root] (omniquant.py 274): INFO layer 29 iter 1 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:45:38 root] (omniquant.py 274): INFO layer 29 iter 2 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:45:51 root] (omniquant.py 274): INFO layer 29 iter 3 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:46:04 root] (omniquant.py 274): INFO layer 29 iter 4 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:46:16 root] (omniquant.py 274): INFO layer 29 iter 5 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:46:29 root] (omniquant.py 274): INFO layer 29 iter 6 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:46:41 root] (omniquant.py 274): INFO layer 29 iter 7 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:46:54 root] (omniquant.py 274): INFO layer 29 iter 8 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:47:06 root] (omniquant.py 274): INFO layer 29 iter 9 loss:1.2858349084854126 norm:nan max memory_allocated 14403.8505859375 
[2025-03-25 15:47:09 root] (omniquant.py 193): INFO === Start quantize layer 30 ===
[2025-03-25 15:47:24 root] (omniquant.py 274): INFO layer 30 iter 0 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:47:37 root] (omniquant.py 274): INFO layer 30 iter 1 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:47:49 root] (omniquant.py 274): INFO layer 30 iter 2 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:48:02 root] (omniquant.py 274): INFO layer 30 iter 3 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:48:14 root] (omniquant.py 274): INFO layer 30 iter 4 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:48:27 root] (omniquant.py 274): INFO layer 30 iter 5 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:48:39 root] (omniquant.py 274): INFO layer 30 iter 6 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:48:52 root] (omniquant.py 274): INFO layer 30 iter 7 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:49:04 root] (omniquant.py 274): INFO layer 30 iter 8 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:49:17 root] (omniquant.py 274): INFO layer 30 iter 9 loss:1.6718661785125732 norm:nan max memory_allocated 14404.7177734375 
[2025-03-25 15:49:19 root] (omniquant.py 193): INFO === Start quantize layer 31 ===
[2025-03-25 15:49:34 root] (omniquant.py 274): INFO layer 31 iter 0 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:49:47 root] (omniquant.py 274): INFO layer 31 iter 1 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:49:59 root] (omniquant.py 274): INFO layer 31 iter 2 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:50:12 root] (omniquant.py 274): INFO layer 31 iter 3 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:50:25 root] (omniquant.py 274): INFO layer 31 iter 4 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:50:37 root] (omniquant.py 274): INFO layer 31 iter 5 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:50:50 root] (omniquant.py 274): INFO layer 31 iter 6 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:51:02 root] (omniquant.py 274): INFO layer 31 iter 7 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:51:15 root] (omniquant.py 274): INFO layer 31 iter 8 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:51:27 root] (omniquant.py 274): INFO layer 31 iter 9 loss:3.1596879959106445 norm:nan max memory_allocated 14405.5849609375 
[2025-03-25 15:51:30 root] (main.py 353): INFO 4254.322941541672
[2025-03-25 15:53:59 root] (main.py 144): INFO wikitext2 : 6.678833484649658
[2025-03-25 15:59:31 root] (main.py 144): INFO c4 : 8.168888092041016
[2025-03-25 18:04:31 root] (main.py 155): INFO {'wikitext2': 6.678833484649658, 'c4': 8.168888092041016, 'results': {'arc_easy': {'acc': 0.6788720538720538, 'acc_stderr': 0.009580787536986797, 'acc_norm': 0.5265151515151515, 'acc_norm_stderr': 0.010245347015573716}, 'piqa': {'acc': 0.763873775843308, 'acc_stderr': 0.00990896589055821, 'acc_norm': 0.7529923830250272, 'acc_norm_stderr': 0.010062268140772634}, 'arc_challenge': {'acc': 0.3779863481228669, 'acc_stderr': 0.0141696645203031, 'acc_norm': 0.3993174061433447, 'acc_norm_stderr': 0.014312094557946704}, 'hellaswag': {'acc': 0.5370444134634534, 'acc_stderr': 0.004976067726432571, 'acc_norm': 0.6919936267675761, 'acc_norm_stderr': 0.004607256752931888}, 'winogrande': {'acc': np.float64(0.6400947119179163), 'acc_stderr': 0.013489609590266804}, 'boolq': {'acc': 0.6957186544342507, 'acc_stderr': 0.00804724137206998}}, 'versions': {'arc_easy': 0, 'piqa': 0, 'arc_challenge': 0, 'hellaswag': 0, 'winogrande': 0, 'boolq': 1}, 'config': {'model': <models.LMClass.LMClass object at 0x7f5875764290>, 'model_args': None, 'num_fewshot': 0, 'limit': None, 'bootstrap_iters': 100000, 'description_dict': None}}
