/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/workspace/AutoGPTQ-bugfix/auto_gptq/nn_modules/triton_utils/kernels.py:357: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @custom_fwd
/workspace/AutoGPTQ-bugfix/auto_gptq/nn_modules/triton_utils/kernels.py:365: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @custom_bwd
/workspace/AutoGPTQ-bugfix/auto_gptq/nn_modules/triton_utils/kernels.py:397: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @custom_fwd(cast_inputs=torch.float16)
usage: main.py [-h] [--model MODEL] [--cache_dir CACHE_DIR]
               [--output_dir OUTPUT_DIR] [--save_dir SAVE_DIR]
               [--resume RESUME] [--real_quant]
               [--calib_dataset {wikitext2,ptb,c4,mix,pile}]
               [--nsamples NSAMPLES] [--batch_size BATCH_SIZE] [--seed SEED]
               [--tasks TASKS] [--eval_ppl] [--num_fewshot NUM_FEWSHOT]
               [--wbits WBITS] [--abits ABITS] [--group_size GROUP_SIZE]
               [--alpha ALPHA] [--let_lr LET_LR] [--lwc_lr LWC_LR] [--wd WD]
               [--epochs EPOCHS] [--let] [--lwc] [--aug_loss] [--symmetric]
               [--disable_zero_point] [--a_dynamic_method {per_token}]
               [--w_dynamic_method {per_channel}] [--limit LIMIT] [--multigpu]
               [--deactive_amp]
               [--attn_implementation {eager,sdpa,flash_attention_2}]
               [--net {opt-125m,opt-1.3b,opt-2.7b,opt-6.7b,opt-13b,opt-30b,opt-66b,llama-7b,llama-13b,llama-30b,llama-65b,Llama-2-7b,Llama-2-13b,Llama-2-70b,Llama-2-7b-chat,Llama-2-13b-chat,llava-llama-2-13b-chat-lightning-preview,falcon-180b,falcon-7b,mixtral-8x7b}]
               [--act-scales ACT_SCALES] [--act-shifts ACT_SHIFTS]
main.py: error: argument --save_dir: expected one argument
['main.py', '--model', '/workspace/volume/inference-soft-data/AE/llm/models/Llama-2-7b-hf', '--eval_ppl', '--save_dir', '--epochs', '0', '--output_dir', './log/Llama-2-7b-w4a7', '--wbits', '4', '--abits', '7', '--lwc', '--let', '--aug_loss', '--use_matrix', '--sf', '0.1', '--tasks', 'piqa,arc_easy,arc_challenge,boolq,hellaswag,winogrande', '--resume', './log/Llama-2-7b-w4a7/omni_parameters.pth']
